#!/usr/bin/env python
# coding: utf-8

# #### Import Libraries

# In[ ]:


get_ipython().run_cell_magic('time', '', 'import pandas as pd\nimport csv\nimport re\nimport urllib.parse\nfrom urllib.request import urlopen\nimport json\nfrom flair.data import Sentence\nfrom flair.nn import Classifier\nfrom chembl_webresource_client.new_client import new_client\nfrom datetime import datetime\nimport zipfile\nimport rdflib\nimport sys\nimport numpy as np\n')


# #### Read the ClinTrials file

# In[ ]:


get_ipython().run_cell_magic('time', '', "df = pd.read_csv('interventional_treatments_output_20250224.csv', sep = '\\t')\n#df.head()\n")


# In[ ]:


print(list(df))


# In[ ]:


print(sys.getsizeof(df))


# #### Fetch all 'conditions' listed in the ClinTrials input file<br>
# clean them to fetch actual conditions

# In[ ]:


get_ipython().run_cell_magic('time', '', '#col1 = \'conditions\' #\'drug_name\'\n#col2 = \'condition_keywords\'#\'drug_description\'\n#info_df = df.loc[:, col1:col2]\n#print(list(info_df))\n\ncounter=0;val_arr=[];col_dict={}\n#col = \'drug_name\' \n#col = \'conditions\'\ncol_arr = [\'drug_name\', \'conditions\']\n#print(df[col]);print(type(df[col]))\nfor col in col_arr:\n    for ele in df[col]:\n        #print(type(ele), \' : \', ele)\n        ele = re.sub(r"\\[\\\'", "", ele);\n        ele = re.sub(r"\\\'\\]", "", ele);\n        splitted_ele = ele.split("\\\', \\\'");#print(ele)\n\n        for val in splitted_ele:\n            #val = re.sub(r\'\\\'\', val)\n            val_arr.append(val)\n        #counter=counter+1\n        #if counter==200:\n        #    break\n    val_arr = list(set(val_arr))\n    col_dict[col] = val_arr\n    val_arr=[];counter=0\n#print(col_dict)\n')


# In[ ]:


for k in col_dict.keys():
    print('number of ',k,'=',len(col_dict[k]), ', size=', sys.getsizeof(col_dict[k]))


# #### Read NCIT data (CSV generated by parsing NCI-Thesaurus file. See owlParser.py for additional details)

# In[ ]:


get_ipython().run_cell_magic('time', '', "dfNCIT = pd.read_csv('ncit.csv', sep = '\\t', header=0)\ndfNCIT = dfNCIT.map(lambda x: x.strip() if isinstance(x, str) else x)\ndfNCIT = dfNCIT.apply(lambda x: x.astype(str).str.upper())\nlist(dfNCIT)\n")


# #### Tokenize the string to identify specific names of compounds and/or diseases

# In[ ]:


def fetchComponents(entity, tokenClass):
    # create a Sentence object
    sentence = Sentence(entity)

    # load biomedical NER tagger
    tagger = Classifier.load("hunflair2")

    # tag sentence
    tagger.predict(sentence)

    tokens=[]
    for token_label in sentence.get_labels():
        #print('label = ', token_label, ' and label.data_point.text = ', token_label.data_point.text)
        if token_label.value == tokenClass:#'Chemical':
            tokens.append(token_label.data_point.text)
    uniq_tokens = list(set(tokens));#print(uniq_tokens)
    return uniq_tokens


# #### Fetch SMILES code from preferred source (Compounds: Any of PubChem, CACTUS, ChEMBL; Diseases: Any of ICD, NCIT)

# In[ ]:


###### EXTRACT SMILES BASED ON COMPOUND NAMES FROM NCI CACTUS OR PUBCHEM ######
def fetchSMILES(val_arr, resource):
    smiles_fetched=0;comp_checked=0;SMILES_dict={};molType_dict={};molID_dict={};uniq_tokens=[]
    idList=[];entityList=[];tokenList=[];smilesList=[];moltypeList=[];
    if resource == 'CACTUS':
        base_url = 'https://cactus.nci.nih.gov/chemical/structure/' 
        property_url = '/smiles'
    if resource == 'PubChem':
        base_url = 'https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/name/'
        property_url = '/property/smiles/TXT'
    if resource == 'ChEMBL':
        molecule = new_client.molecule

    print('will try to fetch SMILES for ', len(val_arr), ' compounds')
    for entity in val_arr:
        comp_checked = comp_checked+1
        if re.search(r'\d*\%',entity):
            entity = re.sub(r'\d*\%','',entity)

        encoded_entity = urllib.parse.quote(entity);#print('urlencoded entity = ', entity);#break;
        
        if resource in ['CACTUS', 'PubChem']:
            complete_url = base_url + encoded_entity + property_url
            response = urlopen(complete_url).read().decode('utf8')
            if response:
                response = re.sub(r'\n\r','', response);response = re.sub(r'\n','', response);
                smiles_fetched = smiles_fetched+1
                SMILES_dict[entity] = response
            else:
                uniq_tokens = fetchComponents(entity, 'Chemical');#print('decomposed as: ', uniq_tokens)
                if len(uniq_tokens)>0:
                    tmp_arr=[];
                    for chemical in uniq_tokens:
                        comp_checked = comp_checked+1
                        chemical = urllib.parse.quote(chemical);#print('urlencoded entity = ', chemical);
                        complete_url = base_url + chemical + property_url
                        response = urlopen(complete_url).read().decode('utf8')
                        if response:
                            response = re.sub(r'\n\r','', response);response = re.sub(r'\n','', response);
                            smiles_fetched = smiles_fetched+1
                            SMILES_dict[entity][chemical] = response
                    #        tmp_arr.append(response)                    
                        else:
                            SMILES_dict[entity][chemical] = 'NO_SMILES'
                    #if len(tmp_arr)>0:
                    #    tmp_arr = list(set(tmp_arr))
                    #    SMILES_dict[entity] = tmp_arr
                    #else:
                    #    SMILES_dict[entity] = 'NO_SMILES'
                else:
                    SMILES_dict[entity]='NO_SMILES'
        #smiles_retrieval_percentage = (smiles_fetched/len(val_arr))*100;
        
        if resource == 'ChEMBL':
            mols = molecule.filter(pref_name__iexact=entity).only('molecule_structures', 'molecule_type', 'molecule_chembl_id')
            if mols:
                smiles_fetched = smiles_fetched+1
                #print('Searched ', entity, 'in pref_name and found: ' , mols)
                for molDict in mols:
                    try : SMILES_dict[entity] = molDict['molecule_structures']['canonical_smiles']
                    except: SMILES_dict[entity] = 'NO_SMILES'
                    molType_dict[entity] = molDict['molecule_type']
                    molID_dict[entity] = molDict['molecule_chembl_id']
            else:
                #print(entity, ' not found in pref_names')
                mols = molecule.filter(molecule_synonyms__molecule_synonym__iexact=entity).only('molecule_structures', 'molecule_type', 'molecule_chembl_id')
                if mols:
                    smiles_fetched = smiles_fetched+1
                    #print('Searched ', encoded_entity, 'in synonyms and found: ', mols)
                    for molDict in mols:
                        try : SMILES_dict[entity] = molDict['molecule_structures']['canonical_smiles']
                        except: SMILES_dict[entity] = 'NO_SMILES'
                        molType_dict[entity] = molDict['molecule_type']
                        molID_dict[entity] = molDict['molecule_chembl_id']
                else:
                    uniq_tokens = fetchComponents(entity, 'Chemical');#print('decomposed as: ', uniq_tokens)

                    if len(uniq_tokens)>0:
                        tmp_arr=[];
                        for chemical in uniq_tokens:
                            comp_checked = comp_checked+1
                            #chemical = urllib.parse.quote(chemical);

                            mols = molecule.filter(pref_name__iexact=chemical).only('molecule_structures', 'molecule_type', 'molecule_chembl_id')
                            if mols:
                                smiles_fetched = smiles_fetched+1
                                #print('Searched ', chemical, 'in pref_name and found: ', mols)
                                for molDict in mols:
                                    try : SMILES_dict[chemical] = molDict['molecule_structures']['canonical_smiles']
                                    except:SMILES_dict[chemical]='NO_SMILES'
                                    molType_dict[chemical] = molDict['molecule_type']
                                    molID_dict[chemical] = molDict['molecule_chembl_id']
                            else:
                                #print(chemical, ' not found in pref_names')
                                mols = molecule.filter(molecule_synonyms__molecule_synonym__iexact=chemical).only('molecule_structures', 'molecule_type', 'molecule_chembl_id')
                                if mols:
                                    smiles_fetched = smiles_fetched+1
                                    #print('Searched ', chemical, 'in synonyms and found: ', mols)
                                    for molDict in mols:
                                        try : SMILES_dict[chemical] = molDict['molecule_structures']['canonical_smiles']
                                        except: SMILES_dict[chemical]='NO_SMILES'
                                        molType_dict[chemical] = molDict['molecule_type']
                                        molID_dict[chemical] = molDict['molecule_chembl_id']
                                else:
                                    #print(chemical, ' not found in synonyms')
                                    SMILES_dict[chemical] = 'NO_SMILES'
                                    molType_dict[chemical] = chemical
                                    chemicalID = re.sub(' ','_', chemical)
                                    molID_dict[chemical] = chemicalID + '_NO_ID'
                    else:
                        #print('SMILES and Mol type could not be fetched for ', entity)
                        SMILES_dict[entity]='NO_SMILES'
                        molType_dict[entity] = entity
                        entityID = re.sub(' ','_', entity)
                        molID_dict[entity] = entityID + '_NO_ID'
            #except:
            #    print('SMILES and Mol type could not be fetched for ', entity)
            #    SMILES_dict[entity]='NO_SMILES'
            #    molType_dict[entity] = entity
            #    entityID = re.sub(' ','_', entity)
            #    molID_dict[entity] = entityID + '_NO_ID'
        
        if len(uniq_tokens)>0:
            for token in uniq_tokens:
                #print(molID_dict[token], entity, token, SMILES_dict[token], molType_dict[token])
                idList.append(molID_dict[token])
                entityList.append(entity)
                tokenList.append(token)
                smilesList.append(SMILES_dict[token])
                moltypeList.append(molType_dict[token])
        else:
            #print(molID_dict[entity], entity, entity, SMILES_dict[entity], molType_dict[entity])
            idList.append(molID_dict[entity])
            entityList.append(entity)
            tokenList.append(entity)
            smilesList.append(SMILES_dict[entity])
            moltypeList.append(molType_dict[entity])
        
        molType_dict={};molID_dict={};uniq_tokens=[];SMILES_dict={}
        
        if (comp_checked%10000 == 0):
            print(comp_checked, ' compounds checked')
            #output_dict = {'id':idList, 'drug_name':entityList, 'molecule':tokenList, 'smiles':smilesList, 'molecule_type':moltypeList}
            #molecule_df = pd.DataFrame(output_dict)
                
    #smiles_retrieval_percentage = (smiles_fetched/comp_checked)*100;
    #print(resource + ' fetched SMILES for ', smiles_fetched, ' i.e. ', smiles_retrieval_percentage, '% of the ', len(val_arr), ' compounds')
    #print(resource + ' fetched SMILES for ', smiles_fetched, ' i.e. ', smiles_retrieval_percentage, '% of the ', comp_checked, ' compounds')
    
    output_dict = {'id':idList, 'drug_name':entityList, 'molecule':tokenList, 'smiles':smilesList, 'molecule_type':moltypeList}
    molecule_df = pd.DataFrame(output_dict)
    #print(molecule_df)
    #return SMILES_dict
    return molecule_df


# In[ ]:


'''
def fetchChEMBL(val_arr, resource):
    smiles_fetched=0;SMILES_dict={}
    if resource == 'ChEMBL':
        molecule = new_client.molecule
        for entity in val_arr:
            if re.search(r'\d*\%',entity):
                entity = re.sub(r'\d*\%','',entity)

            encoded_entity = urllib.parse.quote(entity);
            try:
                mols = molecule.filter(pref_name__iexact=entity).only('molecule_structures', 'molecule_type')
                if mols:
                    #print('Searched ', entity, 'in pref_name and found: ' , mols)
                    for molDict in mols:
                        print(molDict['molecule_structures']['canonical_smiles'])
                        print(molDict['molecule_type'])
                else:
                    print(entity, ' not found in pref_names')
                    mols = molecule.filter(pref_name__iexact=encoded_entity)
                    if mols:print('Searched ', encoded_entity, 'in pref_name and found: ', mols)
                    else:
                        print(encoded_entity, ' not found in pref_names')
                        mols = molecule.filter(molecule_synonyms__molecule_synonym__iexact=entity)
                        if mols: print('Searched ', entity, 'in synonyms and found: ', mols)
                        else:
                            print(entity, ' not found in synonyms')
                            mols = molecule.filter(molecule_synonyms__molecule_synonym__iexact=encoded_entity)
                            if mols:print('Searched ', encoded_entity, 'in synonyms and found: ', mols)
                            else:print(encoded_entity, ' not found in synonyms')
            except:
                print('cannot open')

val_arr = ['Lovastatin']
fetchChEMBL(val_arr, 'ChEMBL')
'''


# #### Run this only if ICD codes are expected for disease/condition terms

# In[ ]:


def fetchICDs(val_arr, resource):
    icds_fetched=0;ICD_code_dict={};ICD_descr_dict={};uniq_disease_tokens=[]
    entityList=[];tokenList=[];codeList=[];descrList=[];
    
    if resource == 'ICD':
        base_url='https://clinicaltables.nlm.nih.gov/api/icd10cm/v3/search?sf=code,name&df=code,name&terms='
    
    for entity in val_arr:
        term = urllib.parse.quote(entity);#re.sub(' ', '+', entity);print(entity)
        complete_url = base_url + term
        
        response = urlopen(complete_url).read().decode('utf8');#print(type(response));break;
        if response:
            response = re.sub(r'\n\r','', response);response = re.sub(r'\n','', response);
            obj = json.loads(response);#print(obj);print(type(obj));break;
            #print(term, ' : ', obj)
            
            if len(obj[1]) != 0:
                ICD_code_dict[entity] = obj[1]
                if len(obj[3]) != 0:
                    ICD_descr_dict[entity] = obj[3]
                else:
                    ICD_descr_dict[entity] = 'NO_ICD_DESCR'
                icds_fetched = icds_fetched + 1    
            else:
                uniq_disease_tokens = fetchComponents(entity, 'Disease');#print('Uniq Disease tokens = ', uniq_disease_tokens)
                if len(uniq_disease_tokens)>0:
                    tmp_arr=[];
                    for disease in uniq_disease_tokens:
                        term = urllib.parse.quote(disease); #re.sub(' ', '+', disease);print(disease)
                        complete_url = base_url + term

                        response = urlopen(complete_url).read().decode('utf8');#print(type(response));break;
                        if response:
                            response = re.sub(r'\n\r','', response);response = re.sub(r'\n','', response);
                            obj = json.loads(response);#print(obj);print(type(obj));break;
                            #print(term, ' : ', obj)

                            if len(obj[1]) != 0 :
                                ICD_code_dict[disease] = obj[1]
                                if len(obj[3]) != 0:
                                    ICD_descr_dict[disease] = obj[3]
                                else:
                                    ICD_descr_dict[disease] = 'NO_ICD_DESCR'
                                icds_fetched = icds_fetched + 1
                            else:
                                ICD_code_dict[disease] = 'NO_ICD_CODE'
                                ICD_descr_dict[disease] = 'NO_ICD_DESCR'
                else:
                    ICD_code_dict[entity] = 'NO_ICD_CODE'
                    ICD_descr_dict[entity] = 'NO_ICD_DESCR'
        else:
            ICD_code_dict[entity] = 'NO_ICD_CODE'                
            ICD_descr_dict[entity] = 'NO_ICD_DESCR'
    
        if len(uniq_disease_tokens)>0:
            for token in uniq_disease_tokens:
                #print(entity, token, ICD_code_dict[token], ICD_descr_dict[token])
                entityList.append(entity)
                tokenList.append(token)
                codeList.append(ICD_code_dict[token])
                descrList.append(ICD_descr_dict[token])
        else:
            #print(entity, entity, ICD_code_dict[entity], ICD_descr_dict[entity])
            entityList.append(entity)
            tokenList.append(entity)
            codeList.append(ICD_code_dict[entity])
            descrList.append(ICD_descr_dict[entity])
    
    icd_retrieval_percentage = (icds_fetched/len(val_arr))*100
    print('ICD data could be retireved for ', icds_fetched, ' i.e. ', icd_retrieval_percentage, '% of the total ', len(val_arr), ' disease terms')
    
    output_dict = {'condition':entityList, 'disease':tokenList, 'icd_codes':codeList, 'icd_descr':descrList}
    disease_df = pd.DataFrame(output_dict)
    return disease_df;

#fetchICDs(['Adult Soft Tissue Sarcoma'], 'ICD')


# #### Fetch row-indices from NCIT where exact match is found for one or more synonyms of diseases/conditions

# In[ ]:


def find_row_indices(df, column_name, match):
    indices = []
    for index, row in df.iterrows():
        #print(row[column_name])
        elements = row[column_name].split('; ');#print(elements);break
        if match in elements:
            indices.append(index)
    return indices


# #### Find matches for conditions in ClinTrials input file in NCIT data i.e. exact-match in any of the three columns - pref-label, display-name, synonyms

# In[ ]:


def fetchNCITs(val_arr, dfNCIT, resource):
    conditionList=['condition'];codeList=['code'];prefNameList=['prefName'];displayNameList=['displayName'];synonymsList=['synonyms'];
    tokenList=['tokens'];output_dict={};index_row=[]
    condition_counter=0
    #print(val_arr)
    for condition in val_arr:
        counter_counter = condition_counter+1
        condition=condition.strip();
        condition=condition.upper();#print('***'+condition+'***')
        for col in list(dfNCIT):
            dfRow = dfNCIT.index[dfNCIT[col] == condition].tolist()
            for i in dfRow:
                index_row.append(i)
            if col == 'synonyms':
                indices = find_row_indices(dfNCIT, 'synonyms', condition)
                for i in indices:
                    index_row.append(i)
        index_row = list(set(index_row))
        #print('condition', condition, 'appears in', index_row)
        
        if len(index_row)>0:
            for index in index_row:
                conditionList.append(condition);tokenList.append(condition)
                codeList.append(dfNCIT.loc[index,'code'])
                prefNameList.append(dfNCIT.loc[index,'prefName'])
                displayNameList.append(dfNCIT.loc[index,'displayName'])
                synonymsList.append(dfNCIT.loc[index,'synonyms']) 
        else:
            uniq_tokens = fetchComponents(condition, 'Disease');
            print('fetched following tokens: ', uniq_tokens)
            if len(uniq_tokens)>0:
                for token in uniq_tokens:
                    token = token.upper()
                    for col in list(dfNCIT):
                        index_row = dfNCIT.index[dfNCIT[col] == token].tolist()                
                        index_row = list(set(index_row))
                    index_row = list(set(index_row))
                    
                    if len(index_row)>0:
                        for index in index_row:
                            conditionList.append(condition);tokenList.append(token)
                            codeList.append(dfNCIT.loc[index,'code'])
                            prefNameList.append(dfNCIT.loc[index,'prefName'])
                            displayNameList.append(dfNCIT.loc[index,'displayName'])
                            synonymsList.append(dfNCIT.loc[index,'synonyms'])
                    else:
                        conditionList.append(condition);tokenList.append(token)
                        codeList.append(re.sub(' ','_',token) + '_NO_MATCH')
                        prefNameList.append('NO_MATCH')
                        displayNameList.append('NO_MATCH')
                        synonymsList.append('NO_MATCH')
            else:
                conditionList.append(condition);tokenList.append('NOT_FOUND')
                codeList.append(re.sub(' ','_',condition) + '_NO_MATCH')
                prefNameList.append('NO_MATCH')
                displayNameList.append('NO_MATCH')
                synonymsList.append('NO_MATCH')
        index_row=[]
    #print('codelist=',len(codeList),'prefName=',len(prefNameList),'disName=',len(displayNameList),'syns=',len(synonymsList),'diseases=',len(conditionList),'tokens=',len(tokenList))
    output_dict = {'code':codeList, 'prefName':prefNameList, 'displayName':displayNameList, 'synonyms':synonymsList, 'diseaseTerms': conditionList, 'disease': tokenList}
    dfMatchedRecords = pd.DataFrame(output_dict)
    return dfMatchedRecords


# In[ ]:


#for k, val_arr in col_dict.items():
#    if k == 'drug_name':
#        for part in range(0, len(val_arr),100):
#            print(val_arr[part:part+100])


# #### Trigger dataframe comparisons and write output file

# In[ ]:


get_ipython().run_cell_magic('time', '', 'now = datetime.now()\ndate_str = now.strftime("%Y-%m-%d").replace(\'-\',\'\')\ninterval = 5000 # Data will be prcessed in chunks of size \'interval\'\n\nfor k, val_arr in col_dict.items():\n    ########## ACTIVATE IF YOU WISH TO PROCESS DRUG-NAMES ########\n    #print(k, val_arr)\n    #if k == \'drug_name\':\n    #    #molecules_df = fetchSMILES(val_arr, \'ChEMBL\');#print(molecules_df)\n    #    for part in range(6000, len(val_arr),1000):\n    #        arr_tmp = val_arr[part:part+1000]\n    #        #molecules_df = fetchSMILES(val_arr, \'ChEMBL\');#print(molecules_df)\n    #        molecules_df = fetchSMILES(arr_tmp, \'ChEMBL\');#print(molecules_df)\n    #        chembl_output_csv = \'interventional_treatments_drugChEMBL_part\' + str(part) + \'_\' + date_str + \'.csv\'\n    #        molecules_df.to_csv(chembl_output_csv, sep=\'\\t\', index=False, header=False, mode=\'a\')\n    ##############################################################\n    \n    ########## ACTIVATE IF YOU WISH TO PROCESS DISEASES ########\n    if k == \'conditions\':\n        #print(val_arr)\n        \n        ########### ACTIVATE IF YOU WISH TO FETCH NCIT CODES (RETRIEVAL FROM A FILE) ###########\n        ##disease_df = fetchNCITs(val_arr, dfNCIT, \'NCIT\')\n        #for part in range(0, len(val_arr),interval):\n        #    arr_tmp = val_arr[part:part+interval]\n        #    disease_df = fetchNCITs(arr_tmp, dfNCIT, \'NCIT\')\n        #    ncit_output_csv = \'interventional_treatments_diseaseNCIT_part\' + str(part) + \'_\' + date_str + \'.csv\'\n        #    disease_df.to_csv(ncit_output_csv, sep=\'\\t\', index=False, header=False, mode=\'a\')\n        ########################################################################################\n        \n        ########### ACTIVATE IF YOU WISH TO FETCH ICD CODES (REPEATED QUERIES TO CLINICAL TABLES SEARCH SERVICE i.e. CTSS API) ###########\n        ##disease_df = fetchICDs(val_arr, \'ICD\')\n        for part in range(0, len(val_arr), interval):\n            arr_tmp= val_arr[part:part+interval]\n            disease_df = fetchICDs(arr_tmp, \'ICD\')\n            icd_output_csv = \'interventional_treatments_diseaseICD_part\' + str(part) + \'_\' + date_str + \'.csv\'\n            disease_df.to_csv(icd_output_csv, sep=\'\\t\', index=False, header=False, mode=\'a\')\n        ########################################################################################\n        \n    ###############################################################\n')


# In[ ]:


disease_df.shape


# In[ ]:


#from chembl_webresource_client.new_client import new_client

#available_resources = [resource for resource in dir(new_client) if not resource.startswith('_')]
#print(available_resources)


# In[ ]:


#df.to_csv(chembl_output_csv, sep='\t', index=False, header=False, mode='a')

